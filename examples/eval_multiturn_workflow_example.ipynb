{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11cac9d",
   "metadata": {},
   "source": [
    "# AymaraAI Multiturn Example\n",
    "\n",
    "This notebook demonstrates a multiturn evaluation workflow with AymaraSDK using thread-based prompt chaining:\n",
    "\n",
    "- Creating an eval with AymaraSDK\n",
    "- Fetching eval prompts\n",
    "- For each prompt, simulating a 3-turn conversation using `client.evals.runs.continue_run` and `continue_thread`\n",
    "- Creating an eval run with the multiturn conversations\n",
    "- Generating and displaying a report\n",
    "\n",
    "## Requirements\n",
    "- Set `OPENAI_API_KEY` and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- Install dependencies: `pip install openai aymara-ai dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0098f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment and imports\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from aymara_ai import AymaraAI\n",
    "from aymara_ai.lib.plot import graph_eval_stats  # type: ignore\n",
    "from aymara_ai.lib.utils import wait_until_complete\n",
    "from aymara_ai.types.eval_prompt import EvalPrompt\n",
    "from aymara_ai.types.eval_response_param import EvalResponseParam\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a088127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment.\")\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19445f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the AymaraSDK client\n",
    "client = AymaraAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850deb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eval(ai_description='Multiturn SDK Example Eval', eval_type='safety', name='multiturn-example-eval', ai_instructions='Engage in a 3-turn conversation, starting with the prompt.', created_at=datetime.datetime(2025, 4, 18, 19, 1, 48, 371000, tzinfo=TzInfo(UTC)), eval_instructions=None, eval_uuid='test.a4a4454a-2fa5-4d18-927b-8544b870a346', is_jailbreak=False, is_sandbox=False, language='en', modality='text', num_prompts=5, prompt_examples=None, status='created', updated_at=datetime.datetime(2025, 4, 18, 19, 1, 48, 371000, tzinfo=TzInfo(UTC)), workspace_uuid=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an eval\n",
    "eval_obj = client.evals.create(\n",
    "    ai_description=\"Multiturn SDK Example Eval\",\n",
    "    ai_instructions=\"Engage in a 3-turn conversation, starting with the prompt.\",\n",
    "    eval_type=\"safety\",\n",
    "    name=\"multiturn-example-eval\",\n",
    "    num_prompts=5,\n",
    ")\n",
    "eval_id = eval_obj.eval_uuid\n",
    "if not eval_id:\n",
    "    raise RuntimeError(\"Eval creation failed.\")\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f42a2a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EvalPrompt(content='Mock prompt 1', prompt_uuid='question.fc144392-e6c6-49c5-844c-1451ed1c0cc8', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 2', prompt_uuid='question.8a50937b-2ac5-483b-9bde-a33071b91739', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 3', prompt_uuid='question.e0c88410-186f-463e-93a4-d560670a13aa', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 4', prompt_uuid='question.60764067-fb85-4e2a-affd-6b4e0f561ec4', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 5', prompt_uuid='question.b5e323f6-7f88-48b3-8776-2a73bb7d66bb', category=None, thread_uuid=None, turn_number=1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch prompts for the eval\n",
    "eval_obj = wait_until_complete(client.evals.get, resource_id=eval_id)\n",
    "prompts_response = client.evals.list_prompts(eval_id)\n",
    "prompts: List[EvalPrompt] = prompts_response.items\n",
    "if not prompts:\n",
    "    raise RuntimeError(\"No prompts found for eval.\")\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1293fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def get_openai_response(messages) -> str:\n",
    "    \"\"\"Get a response from OpenAI's API.\"\"\"\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano-2025-04-14\",\n",
    "        messages=messages,\n",
    "        max_tokens=256,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def answer_prompts(prompts: List[EvalPrompt], history: Dict[str, List[Dict[str, str]]]) -> List[EvalResponseParam]:\n",
    "    \"\"\"Answer the prompts using OpenAI's API.\"\"\"\n",
    "    responses: List[EvalResponseParam] = []\n",
    "    for prompt in prompts:\n",
    "        prompt_text = prompt.content\n",
    "        prompt_uuid = prompt.prompt_uuid\n",
    "        history[prompt_uuid].append({\"role\": \"user\", \"content\": prompt_text})\n",
    "        answer = get_openai_response(history.get(prompt_uuid))\n",
    "        responses.append(EvalResponseParam(content=answer, prompt_uuid=prompt_uuid))\n",
    "\n",
    "        history[prompt_uuid].append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be17ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No more prompts to score.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multiturn thread-based conversation logic (3 turns per prompt)\n",
    "from collections import defaultdict\n",
    "\n",
    "NUM_TURNS = 3\n",
    "\n",
    "\n",
    "conversation_histories: Dict[str, List[Dict[str, str]]] = defaultdict(list)\n",
    "eval_run_uuid = None\n",
    "current_prompts = prompts.copy() if prompts else []\n",
    "# 1. Multiturn loop: continue the thread for NUM_TURNS-1 more turns\n",
    "for turn in range(1, NUM_TURNS):\n",
    "    # Wait for eval run to complete and get new prompts for this turn\n",
    "    responses = answer_prompts(current_prompts, conversation_histories)\n",
    "\n",
    "    # On the last turn, set continue_thread=False to end the conversation\n",
    "    continue_thread = turn < NUM_TURNS - 1\n",
    "    eval_run = client.evals.runs.score_responses(\n",
    "        eval_run_uuid=eval_run_uuid, eval_uuid=eval_id, responses=responses, continue_thread=continue_thread\n",
    "    )\n",
    "\n",
    "    eval_run_uuid = eval_run.eval_run_uuid\n",
    "    scored_responses = eval_run.responses if eval_run.responses else []\n",
    "    current_prompts.clear()\n",
    "    for response in scored_responses:\n",
    "        if response.next_prompt:\n",
    "            # Append the next prompt to the list of prompts\n",
    "            current_prompts.append(response.next_prompt)\n",
    "    if not current_prompts:\n",
    "        display(\"No more prompts to score.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45e1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'question.0fd34b67-e507-432f-a199-f2f04e1f5097': [{'role': 'user',\n",
       "               'content': 'Mock prompt 1'},\n",
       "              {'role': 'assistant',\n",
       "               'content': 'Hello! It looks like you\\'ve mentioned \"Mock prompt 1.\" How can I assist you today? Please provide more details or specify what you\\'d like help with.'}],\n",
       "             'question.60f699ba-474b-4b72-92e6-401687b5f1c5': [{'role': 'user',\n",
       "               'content': 'Mock prompt 2'},\n",
       "              {'role': 'assistant',\n",
       "               'content': 'Certainly! Could you please clarify or specify what you\\'d like me to do with \"Mock prompt 2\"? Are you looking for an example prompt, a response to a prompt, or something else?'}],\n",
       "             'question.e6a784c7-7d4a-44fe-bdfb-7ef55eaf4156': [{'role': 'user',\n",
       "               'content': 'Mock prompt 3'},\n",
       "              {'role': 'assistant',\n",
       "               'content': 'Sure! Could you please provide more details or clarify what you mean by \"Mock prompt 3\"? Are you looking for a sample prompt, a specific type of question, or something else?'}],\n",
       "             'question.af57890c-1a99-4eda-a102-d210a875e97d': [{'role': 'user',\n",
       "               'content': 'Mock prompt 4'},\n",
       "              {'role': 'assistant',\n",
       "               'content': 'Sure! Could you please provide more details or specify what you mean by \"Mock prompt 4\"? Are you looking for an example prompt, a practice exercise, or something else?'}],\n",
       "             'question.26fbcf67-1487-451f-97ef-75c0b827aacc': [{'role': 'user',\n",
       "               'content': 'Mock prompt 5'},\n",
       "              {'role': 'assistant',\n",
       "               'content': 'Certainly! Could you please provide more details or specify what you\\'d like for \"Mock prompt 5\"? For example, are you looking for a writing prompt, a coding prompt, a discussion topic, or something else?'}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df67af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eval run stats\n",
    "graph_eval_stats(eval_runs=eval_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d078e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrompt UUID: question.0fd34b67-e507-432f-a199-f2f04e1f5097'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'user: Mock prompt 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'assistant: Hello! It looks like you\\'ve mentioned \"Mock prompt 1.\" How can I assist you today? Please provide more details or specify what you\\'d like help with.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nPrompt UUID: question.60f699ba-474b-4b72-92e6-401687b5f1c5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'user: Mock prompt 2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'assistant: Certainly! Could you please clarify or specify what you\\'d like me to do with \"Mock prompt 2\"? Are you looking for an example prompt, a response to a prompt, or something else?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nPrompt UUID: question.e6a784c7-7d4a-44fe-bdfb-7ef55eaf4156'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'user: Mock prompt 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'assistant: Sure! Could you please provide more details or clarify what you mean by \"Mock prompt 3\"? Are you looking for a sample prompt, a specific type of question, or something else?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nPrompt UUID: question.af57890c-1a99-4eda-a102-d210a875e97d'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'user: Mock prompt 4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'assistant: Sure! Could you please provide more details or specify what you mean by \"Mock prompt 4\"? Are you looking for an example prompt, a practice exercise, or something else?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nPrompt UUID: question.26fbcf67-1487-451f-97ef-75c0b827aacc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'user: Mock prompt 5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'assistant: Certainly! Could you please provide more details or specify what you\\'d like for \"Mock prompt 5\"? For example, are you looking for a writing prompt, a coding prompt, a discussion topic, or something else?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display conversation histories for each prompt\n",
    "for prompt_uuid, history in conversation_histories.items():\n",
    "    display(f\"\\nPrompt UUID: {prompt_uuid}\")\n",
    "    for msg in history:\n",
    "        display(f\"{msg['role']}: {msg['content'].strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8aaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
