{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AymaraAI Image Safety Eval with EvalRunner and AsyncEvalRunner\n",
    "\n",
    "This notebook demonstrates how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for image safety evaluation with the AymaraAI SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Set `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- Install dependencies:\n",
    "  ```bash\n",
    "  pip install boto3 aymara-ai dotenv pandas requests pillow\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and imports\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import tempfile\n",
    "\n",
    "import boto3  # type: ignore\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from aymara_ai import AymaraAI, AsyncAymaraAI\n",
    "from aymara_ai.lib.runner import EvalRunner, AsyncEvalRunner\n",
    "from aymara_ai.lib.images_utils import display_image_responses\n",
    "from aymara_ai.types.shared_params import FileReference\n",
    "from aymara_ai.types.eval_response_param import EvalResponseParam\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Callables\n",
    "\n",
    "The callable interface takes a prompt string, generates an image using AWS Bedrock, uploads it to Aymara, and returns a FileReference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Bedrock client\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=os.getenv(\"AWS_REGION\", \"us-west-2\"))\n",
    "\n",
    "def generate_image(prompt: str) -> Path:\n",
    "    \"\"\"Generate an image using AWS Bedrock Stability model and return the local file path.\"\"\"\n",
    "    body = json.dumps({\"prompt\": prompt})\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=\"stability.stable-image-core-v1:0\",  # Update if your Bedrock model ID is different\n",
    "        body=body,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\",\n",
    "    )\n",
    "    result = json.loads(response[\"body\"].read())\n",
    "    # The output format may vary; adjust as needed for your Bedrock model\n",
    "    image_b64 = result[\"images\"][0]\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tmp:\n",
    "        image_data = base64.b64decode(image_b64)\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        image.save(tmp.name, format=\"PNG\")\n",
    "        # return the path to the saved image\n",
    "        return Path(tmp.name)\n",
    "\n",
    "\n",
    "\n",
    "# Asynchronous model callable for AsyncEvalRunner\n",
    "async def generate_image_async(prompt: str) -> Path:\n",
    "    image_path = generate_image(prompt)\n",
    "    # Use sync upload in thread for simplicity\n",
    "    return image_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Eval Parameters\n",
    "\n",
    "We will use a basic image safety eval configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_description = \"A helpful AI assistant.\"\n",
    "ai_instructions = \"Please generate a set of images that are safe for work and do not contain any explicit content.\"\n",
    "\n",
    "eval_params = {\n",
    "    \"ai_description\": ai_description,\n",
    "    \"ai_instructions\": ai_instructions,\n",
    "    \"eval_type\": \"safety\",\n",
    "    \"name\": \"image safety eval (runner example)\",\n",
    "    \"modality\": \"image\",\n",
    "    \"num_prompts\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous Evaluation with EvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AymaraAI()\n",
    "runner = EvalRunner(client, generate_image)\n",
    "eval_run = runner.run_eval(eval_params)\n",
    "display(f\"Eval Run ID: {eval_run.eval_run_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Evaluation with AsyncEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async_client = AsyncAymaraAI()\n",
    "runner = AsyncEvalRunner(async_client, generate_image_async)\n",
    "eval_run_async = await runner.run_eval(eval_params)\n",
    "display(f\"Async Eval Run ID: {eval_run_async.eval_run_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for synchronous run\n",
    "from aymara_ai.lib.async_utils import wait_until_complete\n",
    "prompts = client.evals.list_prompts(runner.eval_id).items\n",
    "responses = client.evals.runs.list_responses(runner.run_id).items\n",
    "display_image_responses(\n",
    "    evals=[runner.eval_obj],\n",
    "    eval_prompts={runner.eval_id: prompts},\n",
    "    eval_responses={runner.eval_id: responses},\n",
    "    n_images_per_eval=3\n",
    ")\n",
    "\n",
    "# Display results for async run (uncomment if async run was executed)\n",
    "# prompts_async = (await async_client.evals.list_prompts(eval_run_async.eval_uuid)).items\n",
    "# responses_async = (await async_client.evals.runs.list_responses(eval_run_async.eval_run_uuid)).items\n",
    "# display_image_responses(\n",
    "#     evals=[eval_run_async.eval_obj],\n",
    "#     eval_prompts={eval_run_async.eval_id: prompts_async},\n",
    "#     eval_responses={eval_run_async.eval_id: responses_async},\n",
    "#     n_images_per_eval=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Visualize with graph_eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from aymara_ai.lib.plot import graph_eval_stats  # type: ignore\n",
    "    graph_eval_stats(eval_runs=[eval_run])\n",
    "except ImportError:\n",
    "    display(\"Plotting utility not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for image safety evaluation with the AymaraAI SDK, using a callable interface that generates and uploads images. Use the synchronous runner for simple, blocking workflows, and the async runner for scalable or concurrent evaluation tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
