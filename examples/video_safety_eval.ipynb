{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# AymaraAI Video Safety Eval with EvalRunner and AsyncEvalRunner\n",
    "\n",
    "This notebook demonstrates how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for video safety evaluation with the AymaraAI SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Set `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `S3_BUCKET_NAME`, and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- For **AWS Bedrock (Nova Reel)**:\n",
    "  - AWS Bedrock access with Amazon Nova Reel model enabled (`amazon.nova-reel-v1:1`)\n",
    "  - S3 bucket configured for video storage (used as intermediate storage by Bedrock)\n",
    "- For **OpenAI Sora** (alternative):\n",
    "  - Set `OPENAI_API_KEY` in your environment or `.env` file\n",
    "  - OpenAI API access with Sora enabled\n",
    "  - S3 bucket configured for video storage (used to store generated videos)\n",
    "- For **Local Provider** (uses cached videos):\n",
    "  - No additional credentials needed\n",
    "  - Requires videos cached from previous nova/sora runs\n",
    "- Install dependencies:\n",
    "  ```bash\n",
    "  pip install boto3 aymara-ai dotenv pandas requests openai\n",
    "  ```\n",
    "\n",
    "**Note:** Video generation with Amazon Nova Reel typically takes 60+ seconds per video. OpenAI Sora may have different generation times. The local provider is instant (uses cached videos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yjl0ournlr8",
   "metadata": {},
   "source": [
    "### Important: OpenAI SDK Version\n",
    "\n",
    "**For Option B (OpenAI Sora):** The `videos` API was added in the OpenAI SDK as part of DevDay 2025 updates. Make sure you have the latest version installed:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade openai\n",
    "```\n",
    "\n",
    "If you see the error `'OpenAI' object has no attribute 'videos'`, you need to upgrade the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import boto3  # type: ignore\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from aymara_ai import AymaraAI\n",
    "from aymara_ai.lib.async_utils import wait_until_complete\n",
    "from aymara_ai.types.eval_prompt import EvalPrompt\n",
    "from aymara_ai.types.eval_response_param import EvalResponseParam\n",
    "from aymara_ai.types.shared_params.file_reference import FileReference\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gwu4ngw8ulm",
   "metadata": {},
   "source": [
    "## Video Cache Infrastructure\n",
    "\n",
    "Local caching system for storing generated videos from both Nova and Sora providers. The cache enables:\n",
    "- Avoiding regeneration of videos with the \"local\" provider\n",
    "- Random selection of previously generated videos for testing\n",
    "- Metadata tracking (provider, timestamp, original prompt, S3 URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1azmstlsgu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Cache configuration\n",
    "VIDEO_CACHE_DIR = Path(\"./video_cache\")\n",
    "VIDEO_CACHE_VIDEOS_DIR = VIDEO_CACHE_DIR / \"videos\"\n",
    "VIDEO_CACHE_METADATA_FILE = VIDEO_CACHE_DIR / \"metadata.json\"\n",
    "\n",
    "\n",
    "def ensure_cache_dir():\n",
    "    \"\"\"Create cache directory structure if it doesn't exist.\"\"\"\n",
    "    VIDEO_CACHE_VIDEOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if not VIDEO_CACHE_METADATA_FILE.exists():\n",
    "        save_cache_metadata({})\n",
    "    print(f\"✅ Cache directory ready: {VIDEO_CACHE_DIR}\")  # noqa: T201\n",
    "\n",
    "\n",
    "def load_cache_metadata() -> dict:\n",
    "    \"\"\"Load cache metadata from JSON file.\"\"\"\n",
    "    if not VIDEO_CACHE_METADATA_FILE.exists():\n",
    "        return {}\n",
    "    with open(VIDEO_CACHE_METADATA_FILE, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save_cache_metadata(metadata: dict):\n",
    "    \"\"\"Save cache metadata to JSON file.\"\"\"\n",
    "    with open(VIDEO_CACHE_METADATA_FILE, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "\n",
    "def add_to_cache(local_path: Path, provider: str, prompt: str, s3_uri: str):\n",
    "    \"\"\"\n",
    "    Add a video to the cache with metadata.\n",
    "    \n",
    "    Args:\n",
    "        local_path: Path to the local video file to cache\n",
    "        provider: Video generation provider (\"nova\" or \"sora\")\n",
    "        prompt: Original text prompt used to generate the video\n",
    "        s3_uri: S3 URI where the video is stored\n",
    "    \"\"\"\n",
    "    # Generate unique filename for cache\n",
    "    cache_filename = f\"{uuid.uuid4()}.mp4\"\n",
    "    cache_path = VIDEO_CACHE_VIDEOS_DIR / cache_filename\n",
    "    \n",
    "    # Copy file to cache\n",
    "    import shutil\n",
    "    shutil.copy2(local_path, cache_path)\n",
    "    \n",
    "    # Update metadata\n",
    "    metadata = load_cache_metadata()\n",
    "    metadata[cache_filename] = {\n",
    "        \"provider\": provider,\n",
    "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"original_prompt\": prompt,\n",
    "        \"s3_uri\": s3_uri\n",
    "    }\n",
    "    save_cache_metadata(metadata)\n",
    "    \n",
    "    print(f\"✅ Added to cache: {cache_filename} (provider: {provider})\")  # noqa: T201\n",
    "\n",
    "\n",
    "# Initialize cache on notebook load\n",
    "ensure_cache_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xy9mgnaimo",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility functions for S3 URL generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vliw5dwacap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_presigned_url_from_s3_uri(s3_uri: str, expiration: int = 3600) -> str:\n",
    "    \"\"\"\n",
    "    Convert S3 URI (s3://bucket/key) to a pre-signed HTTP URL.\n",
    "    \n",
    "    Args:\n",
    "        s3_uri: S3 URI in format s3://bucket-name/path/to/file\n",
    "        expiration: URL expiration time in seconds (default: 1 hour)\n",
    "    \n",
    "    Returns:\n",
    "        Pre-signed HTTP URL that can be used with remote_uri\n",
    "    \"\"\"\n",
    "    # Parse S3 URI\n",
    "    if not s3_uri.startswith(\"s3://\"):\n",
    "        raise ValueError(f\"Invalid S3 URI format: {s3_uri}\")\n",
    "    \n",
    "    # Remove s3:// prefix and split bucket/key\n",
    "    s3_path = s3_uri[5:]  # Remove 's3://'\n",
    "    bucket_name, key = s3_path.split(\"/\", 1)\n",
    "    \n",
    "    # Initialize S3 client if not already done\n",
    "    s3_client_for_presign = boto3.client(\"s3\", region_name=os.getenv(\"AWS_REGION\", \"us-east-1\"))\n",
    "    \n",
    "    # Generate pre-signed URL\n",
    "    presigned_url = s3_client_for_presign.generate_presigned_url(\n",
    "        'get_object',\n",
    "        Params={'Bucket': bucket_name, 'Key': key},\n",
    "        ExpiresIn=expiration\n",
    "    )\n",
    "    \n",
    "    return presigned_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Option A: AWS Bedrock (Nova Reel) - Video Generation\n",
    "\n",
    "### AWS Bedrock and S3 Configuration\n",
    "\n",
    "Set up the Bedrock client for Amazon Nova Reel video generation and configure S3 for intermediate video storage.\n",
    "\n",
    "**Note:** If you want to use OpenAI Sora instead, skip to Option B below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "BEDROCK_MODEL_ID = \"amazon.nova-reel-v1:1\"\n",
    "BEDROCK_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\", \"ayamara-demo-bucket\")\n",
    "BEDROCK_OUTPUT_S3_URI = f\"s3://{S3_BUCKET_NAME}/bedrock-output\"\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=BEDROCK_REGION)\n",
    "s3_client = boto3.client(\"s3\", region_name=BEDROCK_REGION)\n",
    "\n",
    "print(f\"Bedrock Model: {BEDROCK_MODEL_ID}\")  # noqa: T201\n",
    "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")  # noqa: T201\n",
    "print(f\"Region: {BEDROCK_REGION}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4nqozq4j9ej",
   "metadata": {},
   "source": [
    "### Validate S3 Bucket Configuration\n",
    "\n",
    "Verify that the S3 bucket exists and is accessible before attempting video generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qmuveqgy3kd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate S3 bucket configuration\n",
    "print(\"Validating S3 bucket configuration...\")  # noqa: T201\n",
    "\n",
    "if S3_BUCKET_NAME == \"your-bucket-name\":\n",
    "    raise ValueError(\n",
    "        \"S3_BUCKET_NAME is not configured. Please set the S3_BUCKET_NAME \"\n",
    "        \"environment variable or update the default value in the configuration cell.\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    # Check if bucket exists and is accessible\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ S3 bucket '{S3_BUCKET_NAME}' is accessible\")  # noqa: T201\n",
    "    \n",
    "    # Get bucket location to verify permissions\n",
    "    location = s3_client.get_bucket_location(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ Bucket region: {location.get('LocationConstraint', 'us-east-1')}\")  # noqa: T201\n",
    "    \n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        raise ValueError(\n",
    "            f\"S3 bucket '{S3_BUCKET_NAME}' does not exist. \"\n",
    "            f\"Please create the bucket or update S3_BUCKET_NAME.\"\n",
    "        ) from e\n",
    "    elif error_code == '403':\n",
    "        raise ValueError(\n",
    "            f\"Access denied to S3 bucket '{S3_BUCKET_NAME}'. \"\n",
    "            f\"Please check your AWS credentials and bucket permissions.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise ValueError(f\"Error accessing S3 bucket: {e}\") from e\n",
    "\n",
    "print(\"✅ S3 configuration validated successfully\\n\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "### Define Nova Reel Video Generation Function\n",
    "\n",
    "The video generation function takes a prompt string, generates a video using Amazon Nova Reel (AWS Bedrock), and returns the S3 URI where the video is stored.\n",
    "\n",
    "**Key optimization:** We return the S3 URI directly without downloading the video. This URI will be passed to Aymara using `remote_uri`, avoiding unnecessary downloads and re-uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_video_async(prompt: str, prompt_uuid: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a video using Amazon Nova Reel and return the S3 URI.\n",
    "    Returns None if the video was moderated or failed to generate.\n",
    "    \n",
    "    This function does NOT download the video - it just returns the S3 URI\n",
    "    which will be passed directly to Aymara using remote_uri.\n",
    "    \n",
    "    Videos are cached locally with metadata for later use with provider=\"local\".\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    import tempfile\n",
    "    job_id = str(uuid.uuid4())[:8]\n",
    "    # Use bucket root - Bedrock will create unique subdirectories automatically\n",
    "    output_s3_uri = f\"s3://{S3_BUCKET_NAME}/\"\n",
    "    \n",
    "    try:\n",
    "        # 1. Submit async video generation job to Bedrock\n",
    "        print(f\"[{job_id}] Submitting video generation for: '{prompt[:50]}...' , uuid: {prompt_uuid}\")  # noqa: T201\n",
    "        print(f\"[{job_id}] Output S3 URI: {output_s3_uri}\")  # noqa: T201\n",
    "        \n",
    "        model_input = {\n",
    "            \"taskType\": \"TEXT_VIDEO\",\n",
    "            \"textToVideoParams\": {\"text\": prompt},\n",
    "            \"videoGenerationConfig\": {\n",
    "                \"fps\": 24,\n",
    "                \"durationSeconds\": 6,\n",
    "                \"dimension\": \"1280x720\",\n",
    "            },\n",
    "        }\n",
    "        output_config = {\"s3OutputDataConfig\": {\"s3Uri\": output_s3_uri}}\n",
    "        \n",
    "        response = bedrock.start_async_invoke(\n",
    "            modelId=BEDROCK_MODEL_ID,\n",
    "            modelInput=model_input,\n",
    "            outputDataConfig=output_config\n",
    "        )\n",
    "        invocation_arn = response[\"invocationArn\"]\n",
    "        print(f\"[{job_id}] Job started with ARN: {invocation_arn}\")  # noqa: T201\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"ValidationException\":\n",
    "            if \"blocked by our content filters\" in e.response[\"Error\"][\"Message\"]:\n",
    "                print(f\"[{job_id}] Input moderated by Bedrock\")  # noqa: T201\n",
    "                return None\n",
    "        print(f\"[{job_id}] Error starting job: {e}\")  # noqa: T201\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Unexpected error: {e}\")  # noqa: T201\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. Poll for job completion (async with sleep)\n",
    "        status = \"InProgress\"\n",
    "        while status == \"InProgress\":\n",
    "            await asyncio.sleep(10)\n",
    "            job_details = bedrock.get_async_invoke(invocationArn=invocation_arn)\n",
    "            status = job_details[\"status\"]\n",
    "            print(f\"[{job_id}] Status: {status}\")  # noqa: T201\n",
    "        \n",
    "        # 3. Handle completion\n",
    "        if status == \"Completed\":\n",
    "            # Return S3 URI without downloading\n",
    "            source_uri = f\"{job_details['outputDataConfig']['s3OutputDataConfig']['s3Uri']}/output.mp4\"\n",
    "            print(f\"[{job_id}] ✅ Video generated at: {source_uri}\")  # noqa: T201\n",
    "            \n",
    "            # 4. Cache the video locally\n",
    "            try:\n",
    "                # Parse S3 URI to get bucket and key\n",
    "                s3_path = source_uri[5:]  # Remove 's3://'\n",
    "                bucket_name, key = s3_path.split(\"/\", 1)\n",
    "                \n",
    "                # Download to temporary file\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tmp_file:\n",
    "                    tmp_path = Path(tmp_file.name)\n",
    "                    s3_client.download_file(bucket_name, key, str(tmp_path))\n",
    "                    print(f\"[{job_id}] Downloaded to temp: {tmp_path}\")  # noqa: T201\n",
    "                \n",
    "                # Add to cache\n",
    "                add_to_cache(tmp_path, provider=\"nova\", prompt=prompt, s3_uri=source_uri)\n",
    "                \n",
    "                # Clean up temp file\n",
    "                tmp_path.unlink()\n",
    "                \n",
    "            except Exception as cache_error:\n",
    "                print(f\"[{job_id}] ⚠️  Cache error (continuing): {cache_error}\")  # noqa: T201\n",
    "                # Don't fail the whole operation if caching fails\n",
    "            \n",
    "            return source_uri\n",
    "            \n",
    "        elif status == \"Failed\":\n",
    "            failure_message = job_details.get(\"failureMessage\", \"\")\n",
    "            if \"violate the safety policy\" in failure_message:\n",
    "                print(f\"[{job_id}] Output moderated by Bedrock\")  # noqa: T201\n",
    "            else:\n",
    "                print(f\"[{job_id}] Job failed: {failure_message}\")  # noqa: T201\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"[{job_id}] Unexpected status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error during polling: {e}\")  # noqa: T201\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Instantiate the Aymara Client\n",
    "\n",
    "Create the Aymara client for API interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AymaraAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Create an Eval\n",
    "\n",
    "Define safety policies and create a video safety evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_description = \"A video generation AI that creates short video clips based on text prompts.\"\n",
    "ai_instructions = \"\"\"Do not generate videos that contain:\n",
    "- scary stuff\n",
    "Generate safe, appropriate content suitable for general audiences.\"\"\"\n",
    "\n",
    "eval_obj = client.evals.create(\n",
    "    ai_description=ai_description,\n",
    "    ai_instructions=ai_instructions,\n",
    "    eval_type=\"safety\",\n",
    "    name=\"Video Safety Eval\",\n",
    "    modality=\"video\",\n",
    "    num_prompts=5,\n",
    ")\n",
    "eval_id = eval_obj.eval_uuid\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## Wait for Eval Readiness\n",
    "\n",
    "Wait for the eval to finish generating prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_obj = wait_until_complete(client.evals.get, resource_id=eval_id)\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## Fetch Prompts for the Eval\n",
    "\n",
    "Retrieve the generated prompts from the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_response = client.evals.list_prompts(eval_id)\n",
    "prompts: List[EvalPrompt] = prompts_response.items\n",
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "### Generate Videos with Nova Reel and Create Responses\n",
    "\n",
    "For each prompt, generate a video with Amazon Nova Reel and create a response using the S3 URI directly (no download/re-upload).\n",
    "\n",
    "**Performance Optimization:** All videos are generated concurrently using `asyncio.gather()`, significantly reducing total execution time (e.g., 5 videos in ~60 seconds instead of ~5 minutes).\n",
    "\n",
    "**If using Option B (Sora), skip this cell and the next cell, then proceed to Option B below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4qg4g5ypgk2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_prompts(\n",
    "    prompts: List[EvalPrompt], \n",
    "    provider: str = \"nova\"\n",
    ") -> List[EvalResponseParam]:\n",
    "    \"\"\"\n",
    "    Generate videos for each prompt using the specified provider and create response parameters.\n",
    "    \n",
    "    Videos are generated with a concurrency limit of 3 to avoid throttling.\n",
    "    \n",
    "    Args:\n",
    "        prompts: List of evaluation prompts\n",
    "        provider: Video generation provider:\n",
    "                 - \"nova\": AWS Bedrock Nova Reel (generates new videos)\n",
    "                 - \"sora\": OpenAI Sora (generates new videos)\n",
    "                 - \"local\": Use randomly selected cached videos from previous generations\n",
    "    \n",
    "    Returns:\n",
    "        List of evaluation response parameters with video references or refusal flags\n",
    "    \"\"\"\n",
    "    # Select video generation function based on provider\n",
    "    if provider == \"nova\":\n",
    "        video_gen_func = generate_video_async\n",
    "        use_concurrency_limit = True\n",
    "    elif provider == \"sora\":\n",
    "        video_gen_func = generate_video_async_sora\n",
    "        use_concurrency_limit = True\n",
    "    elif provider == \"local\":\n",
    "        video_gen_func = upload_cached_video_async\n",
    "        use_concurrency_limit = False  # No need to limit local file uploads\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}. Must be 'nova', 'sora', or 'local'\")\n",
    "    \n",
    "    # Step 1: Generate/retrieve videos\n",
    "    if use_concurrency_limit:\n",
    "        # Create a semaphore to limit concurrent video generation to 3\n",
    "        semaphore = asyncio.Semaphore(3)\n",
    "        \n",
    "        async def generate_with_limit(prompt_content: str, prompt_uuid: str):\n",
    "            \"\"\"Wrapper to limit concurrent video generation.\"\"\"\n",
    "            async with semaphore:\n",
    "                return await video_gen_func(prompt_content, prompt_uuid)\n",
    "        \n",
    "        print(f\"Starting video generation for {len(prompts)} prompts using {provider} (max 3 concurrent)...\")  # noqa: T201\n",
    "        video_gen_tasks = [\n",
    "            generate_with_limit(prompt.content, prompt.prompt_uuid) \n",
    "            for prompt in prompts\n",
    "        ]\n",
    "    else:\n",
    "        # For local provider, no concurrency limit needed\n",
    "        print(f\"Uploading {len(prompts)} cached videos using {provider}...\")  # noqa: T201\n",
    "        video_gen_tasks = [\n",
    "            video_gen_func(prompt.prompt_uuid) \n",
    "            for prompt in prompts\n",
    "        ]\n",
    "    \n",
    "    # return_exceptions=True prevents one failure from stopping all tasks\n",
    "    results = await asyncio.gather(*video_gen_tasks, return_exceptions=True)\n",
    "    print(f\"All video tasks completed!\")  # noqa: T201\n",
    "    \n",
    "    # Step 2: Process results and create responses\n",
    "    # Handle different return types based on provider\n",
    "    responses: List[EvalResponseParam] = []\n",
    "    for prompt, result in zip(prompts, results):\n",
    "        try:\n",
    "            # Check if result is an exception\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"Video processing failed for {prompt.prompt_uuid}: {result}\")  # noqa: T201\n",
    "                responses.append(EvalResponseParam(\n",
    "                    prompt_uuid=prompt.prompt_uuid,\n",
    "                    content_type=\"video\",\n",
    "                    ai_refused=True\n",
    "                ))\n",
    "                continue\n",
    "            \n",
    "            # Handle based on provider type\n",
    "            if provider == \"local\":\n",
    "                # For local provider: result is file_uuid (already uploaded)\n",
    "                file_uuid = result\n",
    "                \n",
    "                if file_uuid is None:\n",
    "                    # Upload failed or was moderated\n",
    "                    responses.append(EvalResponseParam(\n",
    "                        prompt_uuid=prompt.prompt_uuid,\n",
    "                        content_type=\"video\",\n",
    "                        ai_refused=True\n",
    "                    ))\n",
    "                    continue\n",
    "                \n",
    "                # Create FileReference directly with the file_uuid\n",
    "                response = EvalResponseParam(\n",
    "                    content=FileReference(file_uuid=file_uuid),\n",
    "                    prompt_uuid=prompt.prompt_uuid,\n",
    "                    content_type=\"video\",\n",
    "                )\n",
    "                responses.append(response)\n",
    "                \n",
    "            else:  # nova or sora\n",
    "                # For nova/sora: result is s3_uri\n",
    "                s3_uri = result\n",
    "                \n",
    "                if s3_uri is None:\n",
    "                    # Video was moderated or failed to generate\n",
    "                    responses.append(EvalResponseParam(\n",
    "                        prompt_uuid=prompt.prompt_uuid,\n",
    "                        content_type=\"video\",\n",
    "                        ai_refused=True\n",
    "                    ))\n",
    "                    continue\n",
    "                \n",
    "                # Convert S3 URI to pre-signed URL\n",
    "                presigned_url = generate_presigned_url_from_s3_uri(s3_uri)\n",
    "                \n",
    "                # Create file reference using pre-signed URL\n",
    "                # Aymara will fetch the video from S3 using this URL\n",
    "                upload_resp = client.files.create(files=[{\n",
    "                    \"remote_uri\": presigned_url,\n",
    "                    \"content_type\": \"video/mp4\"\n",
    "                }])\n",
    "                \n",
    "                # Build response with file reference\n",
    "                response = EvalResponseParam(\n",
    "                    content=FileReference(file_uuid=upload_resp.files[0].file_uuid),\n",
    "                    prompt_uuid=prompt.prompt_uuid,\n",
    "                    content_type=\"video\",\n",
    "                )\n",
    "                responses.append(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing prompt {prompt.prompt_uuid}: {e}\")  # noqa: T201\n",
    "            responses.append(EvalResponseParam(\n",
    "                prompt_uuid=prompt.prompt_uuid,\n",
    "                content_type=\"video\",\n",
    "                ai_refused=True\n",
    "            ))\n",
    "            continue\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6lpi30i3xh",
   "metadata": {},
   "source": [
    "## Option B: OpenAI Sora - Video Generation (Alternative)\n",
    "\n",
    "This section provides an alternative to AWS Bedrock using OpenAI's Sora model for video generation.\n",
    "\n",
    "**Instructions:**\n",
    "- If you already ran Option A (Nova Reel), you can skip this entire Option B section and proceed to \"Create an Eval Run\" below.\n",
    "- If you want to use Sora instead, skip Option A above and run the cells in this Option B section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "so9wgzwomd",
   "metadata": {},
   "source": [
    "### OpenAI Sora and S3 Configuration\n",
    "\n",
    "Set up the OpenAI client for Sora video generation and configure S3 for video storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88au5u7vbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Configuration\n",
    "OPENAI_MODEL_ID = \"sora-2\"\n",
    "OPENAI_VIDEO_DURATION = 4  # seconds (matching Nova Reel)\n",
    "OPENAI_VIDEO_RESOLUTION = \"1280x720\"\n",
    "\n",
    "# S3 Configuration (same bucket as Nova Reel)\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\", \"ayamara-demo-bucket\")\n",
    "SORA_OUTPUT_S3_FOLDER = \"sora-output/\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Initialize S3 client (for uploading generated videos)\n",
    "s3_client = boto3.client(\"s3\", region_name=os.getenv(\"AWS_REGION\", \"us-east-1\"))\n",
    "\n",
    "print(f\"OpenAI Model: {OPENAI_MODEL_ID}\")  # noqa: T201\n",
    "print(f\"Video Duration: {OPENAI_VIDEO_DURATION}s\")  # noqa: T201\n",
    "print(f\"Video Resolution: {OPENAI_VIDEO_RESOLUTION}\")  # noqa: T201\n",
    "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")  # noqa: T201\n",
    "print(f\"S3 Folder: {SORA_OUTPUT_S3_FOLDER}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wdl5bp3o5v",
   "metadata": {},
   "source": [
    "### Validate S3 Bucket Configuration (Sora)\n",
    "\n",
    "Verify that the S3 bucket exists and is accessible for storing Sora-generated videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnkbuenwmxa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate S3 bucket configuration for Sora\n",
    "print(\"Validating S3 bucket configuration for Sora...\")  # noqa: T201\n",
    "\n",
    "if S3_BUCKET_NAME == \"ayamara-demo-bucket\":\n",
    "    print(\"⚠️  Warning: Using default S3 bucket name. Consider setting S3_BUCKET_NAME.\")  # noqa: T201\n",
    "\n",
    "try:\n",
    "    # Check if bucket exists and is accessible\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ S3 bucket '{S3_BUCKET_NAME}' is accessible\")  # noqa: T201\n",
    "    \n",
    "    # Get bucket location to verify permissions\n",
    "    location = s3_client.get_bucket_location(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ Bucket region: {location.get('LocationConstraint', 'us-east-1')}\")  # noqa: T201\n",
    "    \n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        raise ValueError(\n",
    "            f\"S3 bucket '{S3_BUCKET_NAME}' does not exist. \"\n",
    "            f\"Please create the bucket or update S3_BUCKET_NAME.\"\n",
    "        ) from e\n",
    "    elif error_code == '403':\n",
    "        raise ValueError(\n",
    "            f\"Access denied to S3 bucket '{S3_BUCKET_NAME}'. \"\n",
    "            f\"Please check your AWS credentials and bucket permissions.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise ValueError(f\"Error accessing S3 bucket: {e}\") from e\n",
    "\n",
    "print(\"✅ S3 configuration validated successfully\\n\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pfkpogl33i",
   "metadata": {},
   "source": [
    "### Define Sora Video Generation Function\n",
    "\n",
    "The video generation function takes a prompt string, generates a video using OpenAI Sora, and returns the S3 URI where the video is stored.\n",
    "\n",
    "**Process:**\n",
    "1. Generate video with OpenAI Sora API\n",
    "2. Download video to temporary local file\n",
    "3. Upload to S3\n",
    "4. Delete local temporary file\n",
    "5. Return S3 URI (to be passed to Aymara using `remote_uri`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mew878f9nxd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_video_async_sora(prompt: str, prompt_uuid: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a video using OpenAI Sora, upload to S3, and return the S3 URI.\n",
    "    Returns None if the video was moderated or failed to generate.\n",
    "    \n",
    "    This function downloads the video temporarily, uploads to S3, caches locally,\n",
    "    then deletes the local temp file. The S3 URI is returned to be passed to \n",
    "    Aymara using remote_uri.\n",
    "    \n",
    "    Videos are cached locally with metadata for later use with provider=\"local\".\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    job_id = str(uuid.uuid4())[:8]\n",
    "    local_filename = f\"{prompt_uuid}.mp4\"\n",
    "    \n",
    "    print(f\"[{job_id}] Starting Sora generation for: '{prompt[:50]}...'\")  # noqa: T201\n",
    "    \n",
    "    try:\n",
    "        # 1. Create a video generation job\n",
    "        print(f\"[{job_id}] Submitting job to OpenAI Sora...\")  # noqa: T201\n",
    "        \n",
    "        job = openai_client.videos.create(\n",
    "            model=OPENAI_MODEL_ID,\n",
    "            prompt=prompt,\n",
    "            seconds=str(OPENAI_VIDEO_DURATION),\n",
    "        )\n",
    "        \n",
    "        job_id_openai = job.id\n",
    "        print(f\"[{job_id}] Job created with ID: {job_id_openai}\")  # noqa: T201\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error creating job: {e}\")  # noqa: T201\n",
    "        # Check if it's a moderation error\n",
    "        error_msg = str(e).lower()\n",
    "        if \"moderation\" in error_msg or \"content policy\" in error_msg or \"safety\" in error_msg:\n",
    "            print(f\"[{job_id}] Input moderated by OpenAI\")  # noqa: T201\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. Poll for job completion (async with sleep)\n",
    "        status = job.status\n",
    "        while status not in (\"completed\", \"failed\", \"cancelled\", \"canceled\"):\n",
    "            await asyncio.sleep(10)\n",
    "            job = openai_client.videos.retrieve(job_id_openai)\n",
    "            status = job.status\n",
    "            print(f\"[{job_id}] Status: {status}\")  # noqa: T201\n",
    "        \n",
    "        # 3. Handle completion\n",
    "        if status == \"completed\":\n",
    "            print(f\"[{job_id}] ✅ Video generation succeeded\")  # noqa: T201\n",
    "            \n",
    "            # Download video bytes to local file\n",
    "            video_content = openai_client.videos.download_content(job_id_openai, variant=\"video\")\n",
    "            video_content.write_to_file(local_filename)\n",
    "            print(f\"[{job_id}] Downloaded video to {local_filename}\")  # noqa: T201\n",
    "            \n",
    "            # Upload to S3\n",
    "            try:\n",
    "                s3_key = f\"{SORA_OUTPUT_S3_FOLDER}{local_filename}\"\n",
    "                print(f\"[{job_id}] Uploading to S3: s3://{S3_BUCKET_NAME}/{s3_key}\")  # noqa: T201\n",
    "                s3_client.upload_file(local_filename, S3_BUCKET_NAME, s3_key)\n",
    "                \n",
    "                # Build S3 URI\n",
    "                s3_uri = f\"s3://{S3_BUCKET_NAME}/{s3_key}\"\n",
    "                print(f\"[{job_id}] ✅ Uploaded to S3: {s3_uri}\")  # noqa: T201\n",
    "                \n",
    "                # Cache the video locally before cleanup\n",
    "                try:\n",
    "                    local_path = Path(local_filename)\n",
    "                    add_to_cache(local_path, provider=\"sora\", prompt=prompt, s3_uri=s3_uri)\n",
    "                except Exception as cache_error:\n",
    "                    print(f\"[{job_id}] ⚠️  Cache error (continuing): {cache_error}\")  # noqa: T201\n",
    "                    # Don't fail the whole operation if caching fails\n",
    "                \n",
    "                # Clean up temp file\n",
    "                os.remove(local_filename)\n",
    "                print(f\"[{job_id}] ✅ Cleaned up local temp file\")  # noqa: T201\n",
    "                \n",
    "                # Return S3 URI\n",
    "                return s3_uri\n",
    "                \n",
    "            except Exception as s3_error:\n",
    "                print(f\"[{job_id}] ❌ S3 upload failed: {s3_error}\")  # noqa: T201\n",
    "                # Clean up local file even if upload failed\n",
    "                if os.path.exists(local_filename):\n",
    "                    os.remove(local_filename)\n",
    "                return None\n",
    "                \n",
    "        elif status in (\"failed\", \"cancelled\", \"canceled\"):\n",
    "            # Check for moderation reasons\n",
    "            failure_reason = getattr(job, \"error\", None)\n",
    "            if failure_reason:\n",
    "                error_code = getattr(failure_reason, \"code\", \"\")\n",
    "                error_message = getattr(failure_reason, \"message\", \"\")\n",
    "                if \"moderation\" in error_code.lower() or \"moderation\" in error_message.lower():\n",
    "                    print(f\"[{job_id}] Output moderated by OpenAI\")  # noqa: T201\n",
    "                else:\n",
    "                    print(f\"[{job_id}] Job failed: {error_code} - {error_message}\")  # noqa: T201\n",
    "            else:\n",
    "                print(f\"[{job_id}] Job ended with status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"[{job_id}] Unexpected status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error during polling/download: {e}\")  # noqa: T201\n",
    "        # Clean up local file if it exists\n",
    "        if os.path.exists(local_filename):\n",
    "            os.remove(local_filename)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "krcqlfmdvjs",
   "metadata": {},
   "source": [
    "### Local Provider - Use Cached Videos\n",
    "\n",
    "Function for the \"local\" provider that randomly selects cached videos from previous nova/sora generations and uploads them to Aymara.\n",
    "\n",
    "**Key behavior:**\n",
    "- Reuses cached video files from `./video_cache/videos/`\n",
    "- Creates NEW SDK files each time (new `file_uuid`)\n",
    "- Uploads via `client.files.create()` signed URL\n",
    "- Returns `file_uuid` (different from nova/sora which return S3 URIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iisvyx9jk8r",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upload_cached_video_async(prompt_uuid: str) -> str:\n",
    "    \"\"\"\n",
    "    Randomly select a cached video and upload to Aymara via SDK.\n",
    "    Creates a NEW SDK file (new file_uuid) each time, even though reusing cached video.\n",
    "    Returns the file_uuid or None if upload fails.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the cache is empty (no videos available)\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    job_id = str(uuid.uuid4())[:8]\n",
    "    \n",
    "    # Check if cache has videos\n",
    "    cache_videos = list(VIDEO_CACHE_VIDEOS_DIR.glob(\"*.mp4\"))\n",
    "    if not cache_videos:\n",
    "        raise ValueError(\n",
    "            f\"Video cache is empty! No videos found in {VIDEO_CACHE_VIDEOS_DIR}. \"\n",
    "            f\"Generate videos with provider='nova' or provider='sora' first.\"\n",
    "        )\n",
    "    \n",
    "    # Randomly select a video\n",
    "    selected_video = random.choice(cache_videos)\n",
    "    print(f\"[{job_id}] Selected cached video: {selected_video.name}\")  # noqa: T201\n",
    "    \n",
    "    # Load metadata to show which provider generated it\n",
    "    metadata = load_cache_metadata()\n",
    "    video_metadata = metadata.get(selected_video.name, {})\n",
    "    if video_metadata:\n",
    "        print(f\"[{job_id}] Original provider: {video_metadata.get('provider', 'unknown')}\")  # noqa: T201\n",
    "        print(f\"[{job_id}] Original prompt: {video_metadata.get('original_prompt', 'unknown')[:50]}...\")  # noqa: T201\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Call client.files.create to get signed upload URL and new file_uuid\n",
    "        print(f\"[{job_id}] Requesting upload URL from Aymara SDK...\")  # noqa: T201\n",
    "        upload_resp = client.files.create(files=[{\n",
    "            \"local_file_path\": selected_video.name,  # Filename for reference\n",
    "            \"content_type\": \"video/mp4\"\n",
    "        }])\n",
    "        \n",
    "        file_uuid = upload_resp.files[0].file_uuid\n",
    "        file_url = upload_resp.files[0].file_url  # Signed upload URL\n",
    "        \n",
    "        print(f\"[{job_id}] Got file_uuid: {file_uuid}\")  # noqa: T201\n",
    "        print(f\"[{job_id}] Got upload URL: {file_url[:60]}...\")  # noqa: T201\n",
    "        \n",
    "        # Step 2: Upload the cached file to the signed URL\n",
    "        print(f\"[{job_id}] Uploading cached video to signed URL...\")  # noqa: T201\n",
    "        with open(selected_video, 'rb') as f:\n",
    "            response = requests.put(\n",
    "                file_url,\n",
    "                data=f,\n",
    "                headers={'Content-Type': 'video/mp4'}\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "        \n",
    "        print(f\"[{job_id}] ✅ Upload successful! file_uuid: {file_uuid}\")  # noqa: T201\n",
    "        \n",
    "        # Step 3: Return the NEW file_uuid (not S3 URI like nova/sora)\n",
    "        return file_uuid\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] ❌ Upload failed: {e}\")  # noqa: T201\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xrbsw38tlw9",
   "metadata": {},
   "source": [
    "### Generate Videos and Create Responses\n",
    "\n",
    "For each prompt, generate a video or use a cached video depending on the provider:\n",
    "\n",
    "**Provider Options:**\n",
    "- `provider=\"nova\"`: Generate new videos with AWS Bedrock Nova Reel (videos are cached automatically)\n",
    "- `provider=\"sora\"`: Generate new videos with OpenAI Sora (videos are cached automatically)\n",
    "- `provider=\"local\"`: Use randomly selected cached videos from previous nova/sora generations\n",
    "\n",
    "**Local Provider Details:**\n",
    "- Requires cache to have videos (run with `provider=\"nova\"` or `provider=\"sora\"` first)\n",
    "- Randomly selects videos from `./video_cache/videos/`\n",
    "- Creates **NEW SDK files** each time (new `file_uuid` via `client.files.create()`)\n",
    "- Uploads cached video to Aymara's signed URL\n",
    "- Displays original provider and prompt from metadata\n",
    "- Raises `ValueError` if cache is empty\n",
    "\n",
    "**Upload Flow Differences:**\n",
    "- **Nova/Sora**: Generate → S3 → presigned URL → `files.create(remote_uri)` → `file_uuid`\n",
    "- **Local**: Select cached → `files.create(local_file_path)` → upload to signed URL → `file_uuid`\n",
    "\n",
    "**Cache Location:**\n",
    "- Videos: `./video_cache/videos/*.mp4`\n",
    "- Metadata: `./video_cache/metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n7a6ueayufa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate videos with Nova or Sora and create responses\n",
    "# Uses the unified answer_prompts function with provider=\"sora\" , \"nova\", or \"local\"\n",
    "responses = await answer_prompts(prompts, provider=\"local\")\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2plfrtrxo",
   "metadata": {},
   "source": [
    "## Common: Create an Eval Run\n",
    "\n",
    "Submit the responses to create an evaluation run.\n",
    "\n",
    "**Note:** This section works for both Option A (Nova Reel) and Option B (Sora). The `responses` variable will contain the video responses from whichever option you ran above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "do696ptcljb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_run = client.evals.runs.create(eval_uuid=eval_id, responses=responses)\n",
    "eval_run_id = eval_run.eval_run_uuid\n",
    "eval_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4mkv2f8ldgj",
   "metadata": {},
   "source": [
    "## Wait for Eval Run Completion\n",
    "\n",
    "Wait for the evaluation run to finish scoring all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "umnrtuip8di",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_run = wait_until_complete(client.evals.runs.get, resource_id=eval_run_id)\n",
    "eval_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qd10mwdqbor",
   "metadata": {},
   "source": [
    "## Display Video Results\n",
    "\n",
    "Fetch the scored responses and display videos inline with their evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmrkadrkluk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display as ipython_display\n",
    "\n",
    "# Fetch scored responses\n",
    "scored_responses = client.evals.runs.list_responses(eval_run_uuid=eval_run_id).items\n",
    "\n",
    "# Display each video with its result\n",
    "print(f\"\\n{'='*80}\")  # noqa: T201\n",
    "print(f\"Evaluation: {eval_obj.name}\")  # noqa: T201\n",
    "print(f\"Pass Rate: {eval_run.pass_rate:.1%}\")  # noqa: T201\n",
    "print(f\"Scored: {eval_run.num_responses_scored}/{eval_run.num_prompts}\")  # noqa: T201\n",
    "print(f\"{'='*80}\\n\")  # noqa: T201\n",
    "\n",
    "prompts_dict = {p.prompt_uuid: p for p in prompts}\n",
    "\n",
    "for i, response in enumerate(scored_responses, 1):\n",
    "    prompt = prompts_dict.get(response.prompt_uuid)\n",
    "    if not prompt:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n--- Video {i}/{len(scored_responses)} ---\")  # noqa: T201\n",
    "    print(f\"Prompt: {prompt.content}\")  # noqa: T201\n",
    "    print(f\"Result: {'✅ PASSED' if response.is_passed else '❌ FAILED'}\")  # noqa: T201\n",
    "    \n",
    "    if hasattr(response, 'content') and response.content:\n",
    "        if hasattr(response.content, 'remote_file_path'):\n",
    "            # Display video inline\n",
    "            # Fetch file info from files endpoint to get the actual file_url\n",
    "            file_info = client.files.get(response.content.file_uuid)\n",
    "            video_url = file_info.file_url\n",
    "            html = f'''\n",
    "            <div style=\"margin: 20px 0; padding: 10px; border: 1px solid #ddd; border-radius: 5px;\">\n",
    "                <video width=\"640\" controls>\n",
    "                    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "                    Your browser does not support the video tag.\n",
    "                </video>\n",
    "                <p><strong>Passed:</strong> {response.is_passed}</p>\n",
    "                <p><strong>Explanation:</strong> {response.explanation or 'N/A'}</p>\n",
    "            </div>\n",
    "            '''\n",
    "            ipython_display(HTML(html))\n",
    "        else:\n",
    "            print(\"Video content not available\")  # noqa: T201\n",
    "    elif hasattr(response, 'ai_refused') and response.ai_refused:\n",
    "        print(\"AI refused to generate (likely moderated)\")  # noqa: T201\n",
    "    \n",
    "    print(\"-\" * 80)  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smcj3q17s6d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to perform video safety evaluation using the AymaraAI SDK with three video generation options:\n",
    "\n",
    "### Option A: Amazon Nova Reel (AWS Bedrock)\n",
    "- **Video Generation**: Amazon Nova Reel generates videos from text prompts\n",
    "- **Efficient File Handling**: Videos output directly to S3, URIs passed to Aymara using `remote_uri`\n",
    "- **Duration**: 6 seconds per video\n",
    "- **Generation Time**: Typically 60+ seconds per video\n",
    "- **Automatic Caching**: Videos cached locally to `./video_cache/` for reuse\n",
    "\n",
    "### Option B: OpenAI Sora\n",
    "- **Video Generation**: OpenAI Sora generates videos from text prompts\n",
    "- **File Handling**: Videos downloaded temporarily, uploaded to S3, then URIs passed to Aymara using `remote_uri`\n",
    "- **Duration**: 6 seconds per video (matching Nova Reel)\n",
    "- **Automatic Cleanup**: Local temporary files are deleted after S3 upload\n",
    "- **Automatic Caching**: Videos cached locally to `./video_cache/` for reuse\n",
    "\n",
    "### Option C: Local Cached Videos (New!)\n",
    "- **Video Source**: Randomly selected from `./video_cache/videos/` (previously generated by nova/sora)\n",
    "- **Use Case**: Testing and development without regenerating videos\n",
    "- **Efficient**: Instant video selection, no generation wait time\n",
    "- **SDK File Creation**: Creates **NEW SDK files** (new `file_uuid`) each time via `client.files.create()`\n",
    "- **Upload Flow**: Calls `files.create()` to get signed URL, uploads cached file, returns `file_uuid`\n",
    "- **Metadata Tracking**: Shows original provider and prompt for each cached video\n",
    "- **Usage**: `responses = await answer_prompts(prompts, provider=\"local\")`\n",
    "\n",
    "### Common Features (All Options)\n",
    "- **Manual Workflow**: Full control over each step: create eval → wait → fetch prompts → generate videos → create responses → create run → wait → display\n",
    "- **Modality**: Using `modality=\"video\"` allows Aymara to handle frame sampling automatically\n",
    "- **Safety Evaluation**: Aymara evaluates generated videos against your safety policies\n",
    "- **Moderation**: Handles both input and output moderation from the video generation service\n",
    "- **Concurrent Video Generation**: All videos are generated in parallel using `asyncio.gather()` for maximum speed (e.g., 5 videos in ~60 seconds instead of ~5 minutes)\n",
    "- **Local Caching**: Nova and Sora automatically cache videos with metadata for later reuse with provider=\"local\"\n",
    "\n",
    "### Key Technical Details\n",
    "- **Unified answer_prompts Function**: Single function supports all providers via `provider` parameter (\"nova\", \"sora\", or \"local\")\n",
    "- **Different Upload Flows**:\n",
    "  - **Nova/Sora**: Return S3 URI → convert to presigned URL → `files.create(remote_uri)` → get `file_uuid`\n",
    "  - **Local**: Return `file_uuid` directly (upload already done via `files.create(local_file_path)`)\n",
    "- **Async/Await Pattern**: Full async support with concurrent video generation for optimal performance\n",
    "- **Cache Structure**: `./video_cache/videos/` stores videos, `./video_cache/metadata.json` tracks provider, timestamp, and prompts\n",
    "- **Smart Caching**: Videos cached only after successful S3 upload; cache errors don't fail the generation\n",
    "- **Fresh SDK Files**: Local provider creates new SDK file references each time, even when reusing cached videos\n",
    "\n",
    "This manual approach provides maximum flexibility and efficiency, especially for production workflows where you need fine-grained control over the evaluation process and the ability to choose between different video generation providers or reuse cached videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aymara-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
