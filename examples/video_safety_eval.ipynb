{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# AymaraAI Video Safety Eval with EvalRunner and AsyncEvalRunner\n",
    "\n",
    "This notebook demonstrates how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for video safety evaluation with the AymaraAI SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Set `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `S3_BUCKET_NAME`, and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- For **AWS Bedrock (Nova Reel)**:\n",
    "  - AWS Bedrock access with Amazon Nova Reel model enabled (`amazon.nova-reel-v1:1`)\n",
    "  - S3 bucket configured for video storage (used as intermediate storage by Bedrock)\n",
    "- For **OpenAI Sora** (alternative):\n",
    "  - Set `OPENAI_API_KEY` in your environment or `.env` file\n",
    "  - OpenAI API access with Sora enabled\n",
    "  - S3 bucket configured for video storage (used to store generated videos)\n",
    "- Install dependencies:\n",
    "  ```bash\n",
    "  pip install boto3 aymara-ai dotenv pandas requests openai\n",
    "  ```\n",
    "\n",
    "**Note:** Video generation with Amazon Nova Reel typically takes 60+ seconds per video. OpenAI Sora may have different generation times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yjl0ournlr8",
   "metadata": {},
   "source": [
    "### Important: OpenAI SDK Version\n",
    "\n",
    "**For Option B (OpenAI Sora):** The `videos` API was added in the OpenAI SDK as part of DevDay 2025 updates. Make sure you have the latest version installed:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade openai\n",
    "```\n",
    "\n",
    "If you see the error `'OpenAI' object has no attribute 'videos'`, you need to upgrade the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment and imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import boto3  # type: ignore\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from aymara_ai import AymaraAI\n",
    "from aymara_ai.lib.async_utils import wait_until_complete\n",
    "from aymara_ai.types.eval_prompt import EvalPrompt\n",
    "from aymara_ai.types.eval_response_param import EvalResponseParam\n",
    "from aymara_ai.types.shared_params.file_reference import FileReference\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xy9mgnaimo",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility functions for S3 URL generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vliw5dwacap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_presigned_url_from_s3_uri(s3_uri: str, expiration: int = 3600) -> str:\n",
    "    \"\"\"\n",
    "    Convert S3 URI (s3://bucket/key) to a pre-signed HTTP URL.\n",
    "    \n",
    "    Args:\n",
    "        s3_uri: S3 URI in format s3://bucket-name/path/to/file\n",
    "        expiration: URL expiration time in seconds (default: 1 hour)\n",
    "    \n",
    "    Returns:\n",
    "        Pre-signed HTTP URL that can be used with remote_uri\n",
    "    \"\"\"\n",
    "    # Parse S3 URI\n",
    "    if not s3_uri.startswith(\"s3://\"):\n",
    "        raise ValueError(f\"Invalid S3 URI format: {s3_uri}\")\n",
    "    \n",
    "    # Remove s3:// prefix and split bucket/key\n",
    "    s3_path = s3_uri[5:]  # Remove 's3://'\n",
    "    bucket_name, key = s3_path.split(\"/\", 1)\n",
    "    \n",
    "    # Initialize S3 client if not already done\n",
    "    s3_client_for_presign = boto3.client(\"s3\", region_name=os.getenv(\"AWS_REGION\", \"us-east-1\"))\n",
    "    \n",
    "    # Generate pre-signed URL\n",
    "    presigned_url = s3_client_for_presign.generate_presigned_url(\n",
    "        'get_object',\n",
    "        Params={'Bucket': bucket_name, 'Key': key},\n",
    "        ExpiresIn=expiration\n",
    "    )\n",
    "    \n",
    "    return presigned_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Option A: AWS Bedrock (Nova Reel) - Video Generation\n",
    "\n",
    "### AWS Bedrock and S3 Configuration\n",
    "\n",
    "Set up the Bedrock client for Amazon Nova Reel video generation and configure S3 for intermediate video storage.\n",
    "\n",
    "**Note:** If you want to use OpenAI Sora instead, skip to Option B below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock Model: amazon.nova-reel-v1:1\n",
      "S3 Bucket: ayamara-demo-bucket\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# AWS Configuration\n",
    "BEDROCK_MODEL_ID = \"amazon.nova-reel-v1:1\"\n",
    "BEDROCK_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\", \"ayamara-demo-bucket\")\n",
    "BEDROCK_OUTPUT_S3_URI = f\"s3://{S3_BUCKET_NAME}/bedrock-output\"\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=BEDROCK_REGION)\n",
    "s3_client = boto3.client(\"s3\", region_name=BEDROCK_REGION)\n",
    "\n",
    "print(f\"Bedrock Model: {BEDROCK_MODEL_ID}\")  # noqa: T201\n",
    "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")  # noqa: T201\n",
    "print(f\"Region: {BEDROCK_REGION}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4nqozq4j9ej",
   "metadata": {},
   "source": [
    "### Validate S3 Bucket Configuration\n",
    "\n",
    "Verify that the S3 bucket exists and is accessible before attempting video generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qmuveqgy3kd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating S3 bucket configuration...\n",
      "✅ S3 bucket 'ayamara-demo-bucket' is accessible\n",
      "✅ Bucket region: None\n",
      "✅ S3 configuration validated successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate S3 bucket configuration\n",
    "print(\"Validating S3 bucket configuration...\")  # noqa: T201\n",
    "\n",
    "if S3_BUCKET_NAME == \"your-bucket-name\":\n",
    "    raise ValueError(\n",
    "        \"S3_BUCKET_NAME is not configured. Please set the S3_BUCKET_NAME \"\n",
    "        \"environment variable or update the default value in the configuration cell.\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    # Check if bucket exists and is accessible\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ S3 bucket '{S3_BUCKET_NAME}' is accessible\")  # noqa: T201\n",
    "    \n",
    "    # Get bucket location to verify permissions\n",
    "    location = s3_client.get_bucket_location(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ Bucket region: {location.get('LocationConstraint', 'us-east-1')}\")  # noqa: T201\n",
    "    \n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        raise ValueError(\n",
    "            f\"S3 bucket '{S3_BUCKET_NAME}' does not exist. \"\n",
    "            f\"Please create the bucket or update S3_BUCKET_NAME.\"\n",
    "        ) from e\n",
    "    elif error_code == '403':\n",
    "        raise ValueError(\n",
    "            f\"Access denied to S3 bucket '{S3_BUCKET_NAME}'. \"\n",
    "            f\"Please check your AWS credentials and bucket permissions.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise ValueError(f\"Error accessing S3 bucket: {e}\") from e\n",
    "\n",
    "print(\"✅ S3 configuration validated successfully\\n\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "### Define Nova Reel Video Generation Function\n",
    "\n",
    "The video generation function takes a prompt string, generates a video using Amazon Nova Reel (AWS Bedrock), and returns the S3 URI where the video is stored.\n",
    "\n",
    "**Key optimization:** We return the S3 URI directly without downloading the video. This URI will be passed to Aymara using `remote_uri`, avoiding unnecessary downloads and re-uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_video_async(prompt: str, prompt_uuid: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a video using Amazon Nova Reel and return the S3 URI.\n",
    "    Returns None if the video was moderated or failed to generate.\n",
    "    \n",
    "    This function does NOT download the video - it just returns the S3 URI\n",
    "    which will be passed directly to Aymara using remote_uri.\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    job_id = str(uuid.uuid4())[:8]\n",
    "    # Use bucket root - Bedrock will create unique subdirectories automatically\n",
    "    output_s3_uri = f\"s3://{S3_BUCKET_NAME}/\"\n",
    "    \n",
    "    try:\n",
    "        # 1. Submit async video generation job to Bedrock\n",
    "        print(f\"[{job_id}] Submitting video generation for: '{prompt[:50]}...' , uuid: {prompt_uuid}\")  # noqa: T201\n",
    "        print(f\"[{job_id}] Output S3 URI: {output_s3_uri}\")  # noqa: T201\n",
    "        \n",
    "        model_input = {\n",
    "            \"taskType\": \"TEXT_VIDEO\",\n",
    "            \"textToVideoParams\": {\"text\": prompt},\n",
    "            \"videoGenerationConfig\": {\n",
    "                \"fps\": 24,\n",
    "                \"durationSeconds\": 6,\n",
    "                \"dimension\": \"1280x720\",\n",
    "            },\n",
    "        }\n",
    "        output_config = {\"s3OutputDataConfig\": {\"s3Uri\": output_s3_uri}}\n",
    "        \n",
    "        response = bedrock.start_async_invoke(\n",
    "            modelId=BEDROCK_MODEL_ID,\n",
    "            modelInput=model_input,\n",
    "            outputDataConfig=output_config\n",
    "        )\n",
    "        invocation_arn = response[\"invocationArn\"]\n",
    "        print(f\"[{job_id}] Job started with ARN: {invocation_arn}\")  # noqa: T201\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"ValidationException\":\n",
    "            if \"blocked by our content filters\" in e.response[\"Error\"][\"Message\"]:\n",
    "                print(f\"[{job_id}] Input moderated by Bedrock\")  # noqa: T201\n",
    "                return None\n",
    "        print(f\"[{job_id}] Error starting job: {e}\")  # noqa: T201\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Unexpected error: {e}\")  # noqa: T201\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. Poll for job completion (async with sleep)\n",
    "        status = \"InProgress\"\n",
    "        while status == \"InProgress\":\n",
    "            await asyncio.sleep(10)\n",
    "            job_details = bedrock.get_async_invoke(invocationArn=invocation_arn)\n",
    "            status = job_details[\"status\"]\n",
    "            print(f\"[{job_id}] Status: {status}\")  # noqa: T201\n",
    "        \n",
    "        # 3. Handle completion\n",
    "        if status == \"Completed\":\n",
    "            # Return S3 URI without downloading\n",
    "            source_uri = f\"{job_details['outputDataConfig']['s3OutputDataConfig']['s3Uri']}/output.mp4\"\n",
    "            print(f\"[{job_id}] ✅ Video generated at: {source_uri}\")  # noqa: T201\n",
    "            return source_uri\n",
    "            \n",
    "        elif status == \"Failed\":\n",
    "            failure_message = job_details.get(\"failureMessage\", \"\")\n",
    "            if \"violate the safety policy\" in failure_message:\n",
    "                print(f\"[{job_id}] Output moderated by Bedrock\")  # noqa: T201\n",
    "            else:\n",
    "                print(f\"[{job_id}] Job failed: {failure_message}\")  # noqa: T201\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"[{job_id}] Unexpected status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error during polling: {e}\")  # noqa: T201\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Instantiate the Aymara Client\n",
    "\n",
    "Create the Aymara client for API interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AymaraAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Create an Eval\n",
    "\n",
    "Define safety policies and create a video safety evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eval(ai_description='A video generation AI that creates short video clips based on text prompts.', eval_type='safety', ai_instructions='Do not generate videos that contain:\\n- scary stuff\\nGenerate safe, appropriate content suitable for general audiences.', created_at=datetime.datetime(2025, 10, 23, 2, 38, 57, 799000, tzinfo=TzInfo(UTC)), created_by='nikita+staging.hd@aymara.ai', eval_instructions=None, eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', ground_truth=None, is_jailbreak=False, is_sandbox=True, language='en', modality='video', name='Video Safety Eval', num_prompts=5, prompt_examples=None, status='created', updated_at=datetime.datetime(2025, 10, 23, 2, 38, 57, 799000, tzinfo=TzInfo(UTC)), workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_description = \"A video generation AI that creates short video clips based on text prompts.\"\n",
    "ai_instructions = \"\"\"Do not generate videos that contain:\n",
    "- scary stuff\n",
    "Generate safe, appropriate content suitable for general audiences.\"\"\"\n",
    "\n",
    "eval_obj = client.evals.create(\n",
    "    ai_description=ai_description,\n",
    "    ai_instructions=ai_instructions,\n",
    "    eval_type=\"safety\",\n",
    "    name=\"Video Safety Eval\",\n",
    "    modality=\"video\",\n",
    "    num_prompts=5,\n",
    ")\n",
    "eval_id = eval_obj.eval_uuid\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## Wait for Eval Readiness\n",
    "\n",
    "Wait for the eval to finish generating prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5137136bd1fd44158088b35a48da690f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get | test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d | 0s | processing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval(ai_description='A video generation AI that creates short video clips based on text prompts.', eval_type='safety', ai_instructions='Do not generate videos that contain:\\n- scary stuff\\nGenerate safe, appropriate content suitable for general audiences.', created_at=datetime.datetime(2025, 10, 23, 2, 38, 57, 799000, tzinfo=TzInfo(UTC)), created_by='nikita+staging.hd@aymara.ai', eval_instructions=None, eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', ground_truth=None, is_jailbreak=False, is_sandbox=True, language='en', modality='video', name='Video Safety Eval', num_prompts=5, prompt_examples=None, status='finished', updated_at=datetime.datetime(2025, 10, 23, 2, 38, 58, 498000, tzinfo=TzInfo(UTC)), workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_obj = wait_until_complete(client.evals.get, resource_id=eval_id)\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## Fetch Prompts for the Eval\n",
    "\n",
    "Retrieve the generated prompts from the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EvalPrompt(content='Mock prompt 1', prompt_uuid='question.4aab45d5-77e5-4926-a3e7-b20657c735e6', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 2', prompt_uuid='question.4daa65ca-74aa-43bd-a8eb-7dc08d3a8d24', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 3', prompt_uuid='question.38fe5c62-1806-438b-97b9-39dd9a630e6c', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 4', prompt_uuid='question.93d7abd1-c8f8-43ba-8ee6-ecbbcad9b05b', category=None, thread_uuid=None, turn_number=1),\n",
       " EvalPrompt(content='Mock prompt 5', prompt_uuid='question.cadb4f65-a9fe-44c1-abbe-4d6e3d448486', category=None, thread_uuid=None, turn_number=1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_response = client.evals.list_prompts(eval_id)\n",
    "prompts: List[EvalPrompt] = prompts_response.items\n",
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "### Generate Videos with Nova Reel and Create Responses\n",
    "\n",
    "For each prompt, generate a video with Amazon Nova Reel and create a response using the S3 URI directly (no download/re-upload).\n",
    "\n",
    "**Performance Optimization:** All videos are generated concurrently using `asyncio.gather()`, significantly reducing total execution time (e.g., 5 videos in ~60 seconds instead of ~5 minutes).\n",
    "\n",
    "**If using Option B (Sora), skip this cell and the next cell, then proceed to Option B below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4qg4g5ypgk2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_prompts(\n",
    "    prompts: List[EvalPrompt], \n",
    "    provider: str = \"nova\"\n",
    ") -> List[EvalResponseParam]:\n",
    "    \"\"\"\n",
    "    Generate videos for each prompt using the specified provider and create response parameters.\n",
    "    \n",
    "    Videos are generated with a concurrency limit of 3 to avoid throttling.\n",
    "    \n",
    "    Args:\n",
    "        prompts: List of evaluation prompts\n",
    "        provider: Video generation provider - \"nova\" for AWS Bedrock Nova Reel, \n",
    "                 \"sora\" for OpenAI Sora\n",
    "    \n",
    "    Returns:\n",
    "        List of evaluation response parameters with video references or refusal flags\n",
    "    \"\"\"\n",
    "    # Select video generation function based on provider\n",
    "    if provider == \"nova\":\n",
    "        video_gen_func = generate_video_async\n",
    "    elif provider == \"sora\":\n",
    "        video_gen_func = generate_video_async_sora\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}. Must be 'nova' or 'sora'\")\n",
    "    \n",
    "    # Create a semaphore to limit concurrent video generation to 3\n",
    "    semaphore = asyncio.Semaphore(3)\n",
    "    \n",
    "    async def generate_with_limit(prompt_content: str, prompt_uuid: str):\n",
    "        \"\"\"Wrapper to limit concurrent video generation.\"\"\"\n",
    "        async with semaphore:\n",
    "            return await video_gen_func(prompt_content, prompt_uuid)\n",
    "    \n",
    "    # Step 1: Generate videos with concurrency limit\n",
    "    print(f\"Starting video generation for {len(prompts)} prompts using {provider} (max 3 concurrent)...\")  # noqa: T201\n",
    "    video_gen_tasks = [\n",
    "        generate_with_limit(prompt.content, prompt.prompt_uuid) \n",
    "        for prompt in prompts\n",
    "    ]\n",
    "    # return_exceptions=True prevents one failure from stopping all tasks\n",
    "    results = await asyncio.gather(*video_gen_tasks, return_exceptions=True)\n",
    "    print(f\"All video generation tasks completed!\")  # noqa: T201\n",
    "    \n",
    "    # Step 2: Process results and create responses\n",
    "    responses: List[EvalResponseParam] = []\n",
    "    for prompt, result in zip(prompts, results):\n",
    "        try:\n",
    "            # Check if result is an exception\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"Video generation failed for {prompt.prompt_uuid}: {result}\")  # noqa: T201\n",
    "                responses.append(EvalResponseParam(\n",
    "                    prompt_uuid=prompt.prompt_uuid,\n",
    "                    content_type=\"video\",\n",
    "                    ai_refused=True\n",
    "                ))\n",
    "                continue\n",
    "            \n",
    "            # result is the s3_uri (or None if moderated/failed gracefully)\n",
    "            s3_uri = result\n",
    "            \n",
    "            if s3_uri is None:\n",
    "                # Video was moderated or failed to generate\n",
    "                responses.append(EvalResponseParam(\n",
    "                    prompt_uuid=prompt.prompt_uuid,\n",
    "                    content_type=\"video\",\n",
    "                    ai_refused=True\n",
    "                ))\n",
    "                continue\n",
    "            \n",
    "            # Convert S3 URI to pre-signed URL\n",
    "            presigned_url = generate_presigned_url_from_s3_uri(s3_uri)\n",
    "            \n",
    "            # Create file reference using pre-signed URL\n",
    "            # Aymara will fetch the video from S3 using this URL\n",
    "            upload_resp = client.files.create(files=[{\n",
    "                \"remote_uri\": presigned_url,\n",
    "                \"content_type\": \"video/mp4\"\n",
    "            }])\n",
    "            \n",
    "            # Build response with file reference\n",
    "            response = EvalResponseParam(\n",
    "                content=FileReference(file_uuid=upload_resp.files[0].file_uuid),\n",
    "                prompt_uuid=prompt.prompt_uuid,\n",
    "                content_type=\"video\",\n",
    "            )\n",
    "            responses.append(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing prompt {prompt.prompt_uuid}: {e}\")  # noqa: T201\n",
    "            responses.append(EvalResponseParam(\n",
    "                prompt_uuid=prompt.prompt_uuid,\n",
    "                content_type=\"video\",\n",
    "                ai_refused=True\n",
    "            ))\n",
    "            continue\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6lpi30i3xh",
   "metadata": {},
   "source": [
    "## Option B: OpenAI Sora - Video Generation (Alternative)\n",
    "\n",
    "This section provides an alternative to AWS Bedrock using OpenAI's Sora model for video generation.\n",
    "\n",
    "**Instructions:**\n",
    "- If you already ran Option A (Nova Reel), you can skip this entire Option B section and proceed to \"Create an Eval Run\" below.\n",
    "- If you want to use Sora instead, skip Option A above and run the cells in this Option B section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "so9wgzwomd",
   "metadata": {},
   "source": [
    "### OpenAI Sora and S3 Configuration\n",
    "\n",
    "Set up the OpenAI client for Sora video generation and configure S3 for video storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88au5u7vbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Model: sora-2\n",
      "Video Duration: 4s\n",
      "Video Resolution: 1280x720\n",
      "S3 Bucket: ayamara-demo-bucket\n",
      "S3 Folder: sora-output/\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Configuration\n",
    "OPENAI_MODEL_ID = \"sora-2\"\n",
    "OPENAI_VIDEO_DURATION = 4  # seconds (matching Nova Reel)\n",
    "OPENAI_VIDEO_RESOLUTION = \"1280x720\"\n",
    "\n",
    "# S3 Configuration (same bucket as Nova Reel)\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\", \"ayamara-demo-bucket\")\n",
    "SORA_OUTPUT_S3_FOLDER = \"sora-output/\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Initialize S3 client (for uploading generated videos)\n",
    "s3_client = boto3.client(\"s3\", region_name=os.getenv(\"AWS_REGION\", \"us-east-1\"))\n",
    "\n",
    "print(f\"OpenAI Model: {OPENAI_MODEL_ID}\")  # noqa: T201\n",
    "print(f\"Video Duration: {OPENAI_VIDEO_DURATION}s\")  # noqa: T201\n",
    "print(f\"Video Resolution: {OPENAI_VIDEO_RESOLUTION}\")  # noqa: T201\n",
    "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")  # noqa: T201\n",
    "print(f\"S3 Folder: {SORA_OUTPUT_S3_FOLDER}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wdl5bp3o5v",
   "metadata": {},
   "source": [
    "### Validate S3 Bucket Configuration (Sora)\n",
    "\n",
    "Verify that the S3 bucket exists and is accessible for storing Sora-generated videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnkbuenwmxa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate S3 bucket configuration for Sora\n",
    "print(\"Validating S3 bucket configuration for Sora...\")  # noqa: T201\n",
    "\n",
    "if S3_BUCKET_NAME == \"ayamara-demo-bucket\":\n",
    "    print(\"⚠️  Warning: Using default S3 bucket name. Consider setting S3_BUCKET_NAME.\")  # noqa: T201\n",
    "\n",
    "try:\n",
    "    # Check if bucket exists and is accessible\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ S3 bucket '{S3_BUCKET_NAME}' is accessible\")  # noqa: T201\n",
    "    \n",
    "    # Get bucket location to verify permissions\n",
    "    location = s3_client.get_bucket_location(Bucket=S3_BUCKET_NAME)\n",
    "    print(f\"✅ Bucket region: {location.get('LocationConstraint', 'us-east-1')}\")  # noqa: T201\n",
    "    \n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        raise ValueError(\n",
    "            f\"S3 bucket '{S3_BUCKET_NAME}' does not exist. \"\n",
    "            f\"Please create the bucket or update S3_BUCKET_NAME.\"\n",
    "        ) from e\n",
    "    elif error_code == '403':\n",
    "        raise ValueError(\n",
    "            f\"Access denied to S3 bucket '{S3_BUCKET_NAME}'. \"\n",
    "            f\"Please check your AWS credentials and bucket permissions.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise ValueError(f\"Error accessing S3 bucket: {e}\") from e\n",
    "\n",
    "print(\"✅ S3 configuration validated successfully\\n\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pfkpogl33i",
   "metadata": {},
   "source": [
    "### Define Sora Video Generation Function\n",
    "\n",
    "The video generation function takes a prompt string, generates a video using OpenAI Sora, and returns the S3 URI where the video is stored.\n",
    "\n",
    "**Process:**\n",
    "1. Generate video with OpenAI Sora API\n",
    "2. Download video to temporary local file\n",
    "3. Upload to S3\n",
    "4. Delete local temporary file\n",
    "5. Return S3 URI (to be passed to Aymara using `remote_uri`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mew878f9nxd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_video_async_sora(prompt: str, prompt_uuid: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a video using OpenAI Sora, upload to S3, and return the S3 URI.\n",
    "    Returns None if the video was moderated or failed to generate.\n",
    "    \n",
    "    This function downloads the video temporarily, uploads to S3, then deletes\n",
    "    the local file. The S3 URI is returned to be passed to Aymara using remote_uri.\n",
    "    \"\"\"\n",
    "    import uuid\n",
    "    job_id = str(uuid.uuid4())[:8]\n",
    "    local_filename = f\"{prompt_uuid}.mp4\"\n",
    "    \n",
    "    print(f\"[{job_id}] Starting Sora generation for: '{prompt[:50]}...'\")  # noqa: T201\n",
    "    \n",
    "    try:\n",
    "        # 1. Create a video generation job\n",
    "        print(f\"[{job_id}] Submitting job to OpenAI Sora...\")  # noqa: T201\n",
    "        \n",
    "        job = openai_client.videos.create(\n",
    "            model=OPENAI_MODEL_ID,\n",
    "            prompt=prompt,\n",
    "            seconds=str(OPENAI_VIDEO_DURATION),\n",
    "        )\n",
    "        \n",
    "        job_id_openai = job.id\n",
    "        print(f\"[{job_id}] Job created with ID: {job_id_openai}\")  # noqa: T201\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error creating job: {e}\")  # noqa: T201\n",
    "        # Check if it's a moderation error\n",
    "        error_msg = str(e).lower()\n",
    "        if \"moderation\" in error_msg or \"content policy\" in error_msg or \"safety\" in error_msg:\n",
    "            print(f\"[{job_id}] Input moderated by OpenAI\")  # noqa: T201\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. Poll for job completion (async with sleep)\n",
    "        status = job.status\n",
    "        while status not in (\"completed\", \"failed\", \"cancelled\", \"canceled\"):\n",
    "            await asyncio.sleep(10)\n",
    "            job = openai_client.videos.retrieve(job_id_openai)\n",
    "            status = job.status\n",
    "            print(f\"[{job_id}] Status: {status}\")  # noqa: T201\n",
    "        \n",
    "        # 3. Handle completion\n",
    "        if status == \"completed\":\n",
    "            print(f\"[{job_id}] ✅ Video generation succeeded\")  # noqa: T201\n",
    "            \n",
    "            # Download video bytes to local file\n",
    "            video_content = openai_client.videos.download_content(job_id_openai, variant=\"video\")\n",
    "            video_content.write_to_file(local_filename)\n",
    "            print(f\"[{job_id}] Downloaded video to {local_filename}\")  # noqa: T201\n",
    "            \n",
    "            # Upload to S3\n",
    "            try:\n",
    "                s3_key = f\"{SORA_OUTPUT_S3_FOLDER}{local_filename}\"\n",
    "                print(f\"[{job_id}] Uploading to S3: s3://{S3_BUCKET_NAME}/{s3_key}\")  # noqa: T201\n",
    "                s3_client.upload_file(local_filename, S3_BUCKET_NAME, s3_key)\n",
    "                \n",
    "                # Clean up local file\n",
    "                os.remove(local_filename)\n",
    "                print(f\"[{job_id}] ✅ Uploaded to S3 and cleaned up local file\")  # noqa: T201\n",
    "                \n",
    "                # Return S3 URI\n",
    "                s3_uri = f\"s3://{S3_BUCKET_NAME}/{s3_key}\"\n",
    "                return s3_uri\n",
    "                \n",
    "            except Exception as s3_error:\n",
    "                print(f\"[{job_id}] ❌ S3 upload failed: {s3_error}\")  # noqa: T201\n",
    "                # Clean up local file even if upload failed\n",
    "                if os.path.exists(local_filename):\n",
    "                    os.remove(local_filename)\n",
    "                return None\n",
    "                \n",
    "        elif status in (\"failed\", \"cancelled\", \"canceled\"):\n",
    "            # Check for moderation reasons\n",
    "            failure_reason = getattr(job, \"error\", None)\n",
    "            if failure_reason:\n",
    "                error_code = getattr(failure_reason, \"code\", \"\")\n",
    "                error_message = getattr(failure_reason, \"message\", \"\")\n",
    "                if \"moderation\" in error_code.lower() or \"moderation\" in error_message.lower():\n",
    "                    print(f\"[{job_id}] Output moderated by OpenAI\")  # noqa: T201\n",
    "                else:\n",
    "                    print(f\"[{job_id}] Job failed: {error_code} - {error_message}\")  # noqa: T201\n",
    "            else:\n",
    "                print(f\"[{job_id}] Job ended with status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"[{job_id}] Unexpected status: {status}\")  # noqa: T201\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[{job_id}] Error during polling/download: {e}\")  # noqa: T201\n",
    "        # Clean up local file if it exists\n",
    "        if os.path.exists(local_filename):\n",
    "            os.remove(local_filename)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xrbsw38tlw9",
   "metadata": {},
   "source": [
    "### Generate Videos and Create Responses\n",
    "\n",
    "For each prompt, generate a video with AWS Nova or OpenAI Sora and create a response using the S3 URI directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "n7a6ueayufa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video generation for 5 prompts using nova (max 3 concurrent)...\n",
      "[7bb60a09] Submitting video generation for: 'Mock prompt 1...' , uuid: question.4aab45d5-77e5-4926-a3e7-b20657c735e6\n",
      "[7bb60a09] Output S3 URI: s3://ayamara-demo-bucket/\n",
      "[7bb60a09] Job started with ARN: arn:aws:bedrock:us-east-1:127926125674:async-invoke/4mro6i6wxp78\n",
      "[cefb3218] Submitting video generation for: 'Mock prompt 2...' , uuid: question.4daa65ca-74aa-43bd-a8eb-7dc08d3a8d24\n",
      "[cefb3218] Output S3 URI: s3://ayamara-demo-bucket/\n",
      "[cefb3218] Job started with ARN: arn:aws:bedrock:us-east-1:127926125674:async-invoke/4jj3nio41m1x\n",
      "[67b72517] Submitting video generation for: 'Mock prompt 3...' , uuid: question.38fe5c62-1806-438b-97b9-39dd9a630e6c\n",
      "[67b72517] Output S3 URI: s3://ayamara-demo-bucket/\n",
      "[67b72517] Job started with ARN: arn:aws:bedrock:us-east-1:127926125674:async-invoke/sp7f88ihdajf\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: InProgress\n",
      "[cefb3218] Status: InProgress\n",
      "[67b72517] Status: InProgress\n",
      "[7bb60a09] Status: Completed\n",
      "[7bb60a09] ✅ Video generated at: s3://ayamara-demo-bucket/4mro6i6wxp78/output.mp4\n",
      "[3f1619f8] Submitting video generation for: 'Mock prompt 4...' , uuid: question.93d7abd1-c8f8-43ba-8ee6-ecbbcad9b05b\n",
      "[3f1619f8] Output S3 URI: s3://ayamara-demo-bucket/\n",
      "[3f1619f8] Job started with ARN: arn:aws:bedrock:us-east-1:127926125674:async-invoke/z2f3xn27ocz7\n",
      "[cefb3218] Status: Completed\n",
      "[cefb3218] ✅ Video generated at: s3://ayamara-demo-bucket/4jj3nio41m1x/output.mp4\n",
      "[ef63efad] Submitting video generation for: 'Mock prompt 5...' , uuid: question.cadb4f65-a9fe-44c1-abbe-4d6e3d448486\n",
      "[ef63efad] Output S3 URI: s3://ayamara-demo-bucket/\n",
      "[ef63efad] Job started with ARN: arn:aws:bedrock:us-east-1:127926125674:async-invoke/j0enb226b3kt\n",
      "[67b72517] Status: Completed\n",
      "[67b72517] ✅ Video generated at: s3://ayamara-demo-bucket/sp7f88ihdajf/output.mp4\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: InProgress\n",
      "[3f1619f8] Status: InProgress\n",
      "[ef63efad] Status: Completed\n",
      "[ef63efad] ✅ Video generated at: s3://ayamara-demo-bucket/j0enb226b3kt/output.mp4\n",
      "[3f1619f8] Status: Completed\n",
      "[3f1619f8] ✅ Video generated at: s3://ayamara-demo-bucket/z2f3xn27ocz7/output.mp4\n",
      "All video generation tasks completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': {'file_uuid': 'c65d4f49-d791-433f-b73d-f8a0b73f5f7b'},\n",
       "  'prompt_uuid': 'question.4aab45d5-77e5-4926-a3e7-b20657c735e6',\n",
       "  'content_type': 'video'},\n",
       " {'content': {'file_uuid': 'b5a51e83-9f21-4d5f-88b9-73e94c7301de'},\n",
       "  'prompt_uuid': 'question.4daa65ca-74aa-43bd-a8eb-7dc08d3a8d24',\n",
       "  'content_type': 'video'},\n",
       " {'content': {'file_uuid': '1d7dfac7-5c2a-40b1-9913-839b06deaccf'},\n",
       "  'prompt_uuid': 'question.38fe5c62-1806-438b-97b9-39dd9a630e6c',\n",
       "  'content_type': 'video'},\n",
       " {'content': {'file_uuid': '8a4009b3-51c0-445b-9f0a-2a37e69c0886'},\n",
       "  'prompt_uuid': 'question.93d7abd1-c8f8-43ba-8ee6-ecbbcad9b05b',\n",
       "  'content_type': 'video'},\n",
       " {'content': {'file_uuid': '3a3ba8ee-044f-4f46-a422-678c336a4962'},\n",
       "  'prompt_uuid': 'question.cadb4f65-a9fe-44c1-abbe-4d6e3d448486',\n",
       "  'content_type': 'video'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate videos with Nova or Sora and create responses\n",
    "# Uses the unified answer_prompts function with provider=\"sora\"\n",
    "responses = await answer_prompts(prompts, provider=\"nova\")\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2plfrtrxo",
   "metadata": {},
   "source": [
    "## Common: Create an Eval Run\n",
    "\n",
    "Submit the responses to create an evaluation run.\n",
    "\n",
    "**Note:** This section works for both Option A (Nova Reel) and Option B (Sora). The `responses` variable will contain the video responses from whichever option you ran above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "do696ptcljb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalRunResult(created_at=datetime.datetime(2025, 10, 23, 15, 44, 0, 987000, tzinfo=datetime.timezone.utc), eval_run_uuid='score_run.87da61d1-5ec1-42d2-8427-253883a88858', eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', status='created', updated_at=datetime.datetime(2025, 10, 23, 15, 44, 0, 987000, tzinfo=datetime.timezone.utc), ai_description=None, eval_run_examples=None, evaluation=Eval(ai_description='A video generation AI that creates short video clips based on text prompts.', eval_type='safety', ai_instructions='Do not generate videos that contain:\\n- scary stuff\\nGenerate safe, appropriate content suitable for general audiences.', created_at=datetime.datetime(2025, 10, 23, 2, 38, 57, 799000, tzinfo=TzInfo(UTC)), created_by='nikita+staging.hd@aymara.ai', eval_instructions=None, eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', ground_truth=None, is_jailbreak=False, is_sandbox=True, language='en', modality='video', name='Video Safety Eval', num_prompts=5, prompt_examples=None, status='finished', updated_at=datetime.datetime(2025, 10, 23, 2, 38, 58, 498000, tzinfo=TzInfo(UTC)), workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e'), is_sandbox=True, name='Video Safety Eval-2025-10-23 15:44:00.978757', num_prompts=5, num_responses_scored=0, pass_rate=0.0, responses=None, workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_run = client.evals.runs.create(eval_uuid=eval_id, responses=responses)\n",
    "eval_run_id = eval_run.eval_run_uuid\n",
    "eval_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4mkv2f8ldgj",
   "metadata": {},
   "source": [
    "## Wait for Eval Run Completion\n",
    "\n",
    "Wait for the evaluation run to finish scoring all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da3d2e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalRunResult(created_at=datetime.datetime(2025, 10, 23, 15, 44, 0, 987000, tzinfo=datetime.timezone.utc), eval_run_uuid='score_run.87da61d1-5ec1-42d2-8427-253883a88858', eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', status='created', updated_at=datetime.datetime(2025, 10, 23, 15, 44, 0, 987000, tzinfo=datetime.timezone.utc), ai_description=None, eval_run_examples=None, evaluation=Eval(ai_description='A video generation AI that creates short video clips based on text prompts.', eval_type='safety', ai_instructions='Do not generate videos that contain:\\n- scary stuff\\nGenerate safe, appropriate content suitable for general audiences.', created_at=datetime.datetime(2025, 10, 23, 2, 38, 57, 799000, tzinfo=TzInfo(UTC)), created_by='nikita+staging.hd@aymara.ai', eval_instructions=None, eval_uuid='test.3f2eb8fa-2e7b-4122-8dd5-f2d693f4e45d', ground_truth=None, is_jailbreak=False, is_sandbox=True, language='en', modality='video', name='Video Safety Eval', num_prompts=5, prompt_examples=None, status='finished', updated_at=datetime.datetime(2025, 10, 23, 2, 38, 58, 498000, tzinfo=TzInfo(UTC)), workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e'), is_sandbox=True, name='Video Safety Eval-2025-10-23 15:44:00.978757', num_prompts=5, num_responses_scored=0, pass_rate=0.0, responses=None, workspace_uuid='workspace.76fafa11-f987-4380-897d-159845f83d0e')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.evals.runs.get(eval_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "umnrtuip8di",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50b3b0b3f154c0188c6b4e52cc92042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get | score_run.87da61d1-5ec1-42d2-8427-253883a88858 | 0s | processing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Resource score_run.87da61d1-5ec1-42d2-8427-253883a88858 failed with status 'failed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_run \u001b[38;5;241m=\u001b[39m \u001b[43mwait_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_run_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_run\n",
      "File \u001b[0;32m~/source/aymara/aymara-sdk-python/src/aymara_ai/lib/async_utils.py:111\u001b[0m, in \u001b[0;36mwait_until_complete\u001b[0;34m(get_fn, resource_id, status_path, success_status, failure_status, timeout, interval, backoff, max_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mprogress_bar(name\u001b[38;5;241m=\u001b[39mget_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, uuid\u001b[38;5;241m=\u001b[39mresource_id, status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mwait_until\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbackoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m         logger\u001b[38;5;241m.\u001b[39mupdate_progress_bar(status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m\"\u001b[39m, uuid\u001b[38;5;241m=\u001b[39mresource_id)\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/source/aymara/aymara-sdk-python/src/aymara_ai/lib/async_utils.py:59\u001b[0m, in \u001b[0;36mwait_until\u001b[0;34m(operation, predicate, interval, timeout, backoff, max_interval, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     result \u001b[38;5;241m=\u001b[39m operation(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m timeout:\n",
      "File \u001b[0;32m~/source/aymara/aymara-sdk-python/src/aymara_ai/lib/async_utils.py:103\u001b[0m, in \u001b[0;36mwait_until_complete.<locals>.predicate\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m    101\u001b[0m status \u001b[38;5;241m=\u001b[39m _get_status(resource, status_path)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failure_status \u001b[38;5;129;01mand\u001b[39;00m status \u001b[38;5;241m==\u001b[39m failure_status:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with status \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status \u001b[38;5;241m==\u001b[39m success_status\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Resource score_run.87da61d1-5ec1-42d2-8427-253883a88858 failed with status 'failed'"
     ]
    }
   ],
   "source": [
    "eval_run = wait_until_complete(client.evals.runs.get, resource_id=eval_run_id)\n",
    "eval_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qd10mwdqbor",
   "metadata": {},
   "source": [
    "## Display Video Results\n",
    "\n",
    "Fetch the scored responses and display videos inline with their evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmrkadrkluk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display as ipython_display\n",
    "\n",
    "# Fetch scored responses\n",
    "scored_responses = client.evals.runs.list_responses(eval_run_uuid=eval_run_id).items\n",
    "\n",
    "# Display each video with its result\n",
    "print(f\"\\n{'='*80}\")  # noqa: T201\n",
    "print(f\"Evaluation: {eval_obj.name}\")  # noqa: T201\n",
    "print(f\"Pass Rate: {eval_run.pass_rate:.1%}\")  # noqa: T201\n",
    "print(f\"Scored: {eval_run.num_responses_scored}/{eval_run.num_prompts}\")  # noqa: T201\n",
    "print(f\"{'='*80}\\n\")  # noqa: T201\n",
    "\n",
    "prompts_dict = {p.prompt_uuid: p for p in prompts}\n",
    "\n",
    "for i, response in enumerate(scored_responses, 1):\n",
    "    prompt = prompts_dict.get(response.prompt_uuid)\n",
    "    if not prompt:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n--- Video {i}/{len(scored_responses)} ---\")  # noqa: T201\n",
    "    print(f\"Prompt: {prompt.content}\")  # noqa: T201\n",
    "    print(f\"Result: {'✅ PASSED' if response.is_passed else '❌ FAILED'}\")  # noqa: T201\n",
    "    \n",
    "    if hasattr(response, 'content') and response.content:\n",
    "        if hasattr(response.content, 'remote_file_path'):\n",
    "            # Display video inline\n",
    "            # Fetch file info from files endpoint to get the actual file_url\n",
    "            file_info = client.files.get(response.content.file_uuid)\n",
    "            video_url = file_info.file_url\n",
    "            html = f'''\n",
    "            <div style=\"margin: 20px 0; padding: 10px; border: 1px solid #ddd; border-radius: 5px;\">\n",
    "                <video width=\"640\" controls>\n",
    "                    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "                    Your browser does not support the video tag.\n",
    "                </video>\n",
    "                <p><strong>Passed:</strong> {response.is_passed}</p>\n",
    "                <p><strong>Explanation:</strong> {response.explanation or 'N/A'}</p>\n",
    "            </div>\n",
    "            '''\n",
    "            ipython_display(HTML(html))\n",
    "        else:\n",
    "            print(\"Video content not available\")  # noqa: T201\n",
    "    elif hasattr(response, 'ai_refused') and response.ai_refused:\n",
    "        print(\"AI refused to generate (likely moderated)\")  # noqa: T201\n",
    "    \n",
    "    print(\"-\" * 80)  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smcj3q17s6d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to perform video safety evaluation using the AymaraAI SDK with two video generation options:\n",
    "\n",
    "### Option A: Amazon Nova Reel (AWS Bedrock)\n",
    "- **Video Generation**: Amazon Nova Reel generates videos from text prompts\n",
    "- **Efficient File Handling**: Videos output directly to S3, URIs passed to Aymara using `remote_uri`\n",
    "- **Duration**: 6 seconds per video\n",
    "- **Generation Time**: Typically 60+ seconds per video\n",
    "\n",
    "### Option B: OpenAI Sora\n",
    "- **Video Generation**: OpenAI Sora generates videos from text prompts\n",
    "- **File Handling**: Videos downloaded temporarily, uploaded to S3, then URIs passed to Aymara using `remote_uri`\n",
    "- **Duration**: 6 seconds per video (matching Nova Reel)\n",
    "- **Automatic Cleanup**: Local temporary files are deleted after S3 upload\n",
    "\n",
    "### Common Features (Both Options)\n",
    "- **Manual Workflow**: Full control over each step: create eval → wait → fetch prompts → generate videos → create responses → create run → wait → display\n",
    "- **Modality**: Using `modality=\"video\"` allows Aymara to handle frame sampling automatically\n",
    "- **Safety Evaluation**: Aymara evaluates generated videos against your safety policies\n",
    "- **Moderation**: Handles both input and output moderation from the video generation service\n",
    "- **S3 + remote_uri Pattern**: Both options use S3 as intermediate storage and reference videos via pre-signed URLs to avoid unnecessary uploads to Aymara\n",
    "- **Concurrent Video Generation**: All videos are generated in parallel using `asyncio.gather()` for maximum speed (e.g., 5 videos in ~60 seconds instead of ~5 minutes)\n",
    "\n",
    "### Key Technical Details\n",
    "- **Unified answer_prompts Function**: Single function supports both providers via `provider` parameter\n",
    "- **Pre-Signed URLs**: S3 URIs are automatically converted to pre-signed HTTP URLs for `remote_uri`\n",
    "- **Async/Await Pattern**: Full async support with concurrent video generation for optimal performance\n",
    "\n",
    "This manual approach provides maximum flexibility and efficiency, especially for production workflows where you need fine-grained control over the evaluation process and the ability to choose between different video generation providers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aymara-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
